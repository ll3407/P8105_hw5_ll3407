---
title: "p8105_hw5_ll3407"
output: github_document
date: "2022-11-10"
---

```{r, include= FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(rvest)
library(purrr)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


##Problem 1

```{r, eval = FALSE, include= FALSE}
file_name = list.files(path = "./data", 
                       pattern = ".csv", 
                       all.files = FALSE, 
                       full.names = FALSE, 
                       recursive = FALSE, 
                       ignore.case = FALSE,
                       include.dirs = FALSE, 
                       no.. = FALSE) %>% view()
    file_name_2 = 
      list(
        arm = str_extract_all(file_name,"[c-e][o-x][n-p]"), 
        subject_id = str_extract_all(file_name, "[0-9]{1,2}")) %>% view()
  
```

```{r}
dataframe = file_name %>% 
  map_df(~read_csv(file.path("./data", .))) %>% 
  bind_cols(file_name) %>% 
  bind_cols(file_name_2) %>% 
  rename(arm = c..con....con....con....con....con....con....con....con....con...) %>% 
  rename(subject_id = c..01....02....03....04....05....06....07....08....09....10...) %>% 
  rename(file =x) %>% 
  pivot_longer(week_1:week_8,
               names_to = "week",
               values_to = "estimate")%>% 
  group_by(file)

```

```{r}
dataframe %>% ggplot(aes(x = week, y = estimate))+geom_line()
```

##Problem 2

# Input dataset and  create variable "city_state"
```{r}
homicide = read_csv(file = "./data2/homicide-data.csv") %>%
  janitor::clean_names() %>% 
  unite("city_state",c("city", "state"), sep = ",") 
  
head(homicide, n =30) %>% view()  
  
```
# summarize total number of homicide by city and unsolved homicide by city
```{r}
total = homicide %>% 
  group_by(city_state) %>%
  summarize(count=n())%>%
  rename(total_number = count) 

unsolved = homicide %>% 
    filter(disposition != "Closed by arrest") %>% 
    group_by(city_state) %>% 
    summarize(count=n()) %>% 
    rename(unsolved_number = count) 
```

#Combine unsolved and total homicide dataset by city_state, drop a city with 'NA' in unsolved homicides, and make a list
```{r}
homicide_2 = left_join(total, unsolved, by = "city_state") %>% 
  arrange(desc(unsolved_number)) %>% 
  filter(unsolved_number != 'NA') %>% view()


homicide_list<-vector("list",nrow(homicide_2))
for (i in 1:nrow(homicide_2)){
  homicide_list[[i]]<-homicide_2[i,]
} 

```

#Baltimore unsolved prop test
```{r}
Baltimore_2 =prop.test(x = 1825, n = 2827, p = NULL, 
    alternative =   c("two.sided"),
    conf.level = 0.95, correct = TRUE ) %>% 
  broom::tidy() %>% 
  select(estimate, conf.low, conf.high)
```

# function of prop.test 
```{r}
prop = function(a){
    
    test = prop.test(n = a$total_number, x = a$unsolved_number, p = NULL, 
    alternative =   c("two.sided"),
    conf.level = 0.95, correct = TRUE ) 
    
  broom::tidy(test) %>% 
  select(estimate, conf.low, conf.high)
  
}

```

#Use map to list columns and unnest 
```{r}
homicide_3 = 
  homicide_2 %>% 
  mutate(
  estimate_dfs =  map(.x = homicide_list, ~prop(.x), bind_rows)) %>% 
  unnest(estimate_dfs)

```

#Plot for estimate and CIs for each city
```{r fig.width=20,fig.height=5}
library("ggplot2")
  homicide_3 %>% 
  mutate(proportion = round(estimate,3))%>% 
  ggplot(aes(reorder(city_state,proportion), y = proportion)) + geom_point() + geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  labs(
    title = "Plot of unsolved homicide proportions",
    x = "City",
    y = "Proportions and 95% CIs of unsolved homicides")


```



## Problem 3
# t.test for normal distribution (mu=0)
```{r}
set.seed(1)

normal = function(n = 30, mu = 0, sigma = 5){
  x = rnorm(n = 30, mean = mu, sd = sigma)
  
  t.test(x, alternative = c("two.sided"),
         mu = 0, paired = FALSE, var.equal = FALSE,
         conf.level = 0.95) %>% 
    broom::tidy() %>% 
    select(estimate, p.value)
  
}

output = vector("list", length = 5000)
for (i in 1:5000){
  output[[i]] = normal(n=30, mu=0, sigma=5)
}

bind_rows(output) %>% view()
```

## t.test for normal distribution (mu=1-6)
```{r}
normal2 = function(n = 30, mu, sigma = 5){
  x = rnorm(n = 30, mean = mu, sd = sigma)
  
  t.test(x, alternative = c("two.sided"),
         mu = 0, paired = FALSE, var.equal = FALSE,
         conf.level = 0.95) %>% 
    broom::tidy() %>% 
    select(estimate, p.value)
  
}

```

```{r}
normal_df = 
  tibble(u = c(1,2,3,4,5,6)) %>% 
  mutate(
    output_lists = map(.x = u, ~rerun(5000, normal2(mu =.x))), 
    estimate_dfs =  map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs) 
```

# make a plot showing the proportion of times the null was rejected
```{r}
power = normal_df %>% group_by(u) %>% count(n_obs = (p.value<0.05)) %>% filter(n_obs == "TRUE") %>% rename(number = n) %>% mutate(count = as.numeric(number)) %>% select(-number) 

power_list<-vector("list", nrow(power))
for (i in 1:nrow(power)){
  power_list[[i]]<-power[i,]
}


prop_2 = function(b){
  prop.test(x = b$count, n = 5000, p = NULL, 
    alternative =   c("two.sided"),
    conf.level = 0.95, correct = TRUE ) %>% 
    broom::tidy() %>%
    select(estimate) %>% 
    rename(power = estimate)
  
}

output_3 = vector("list",length = 6)
for(i in 1:6){
  output_3[[i]] = prop_2(power_list[[i]])
}
estimate_df = bind_rows(output_3)
power_df = bind_cols(power, estimate_df)

    
```

# plot of effect size and power
```{r}
power_plot = power_df %>% 
  ggplot(aes(x = u, y = power))+geom_point()

power_plot
```
The power increases with the increment of effect size, and approximately approaches to 1 when u is over 4.

# plot of mu_hat and mu
```{r}
normal3 = function(n = 30, mu, sigma = 5){
  x = rnorm(n = 30, mean = mu, sd = sigma)
  
  tibble(
    mu_hat = mean(x)
  )
  
}

normal_df_3 = 
  tibble(u = c(1,2,3,4,5,6)) %>% 
  mutate(
    output_lists = map(.x = u, ~rerun(5000, normal3(mu =.x))), 
    estimate_dfs =  map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs)

mu_hat_plot = normal_df_3 %>% 
  ggplot(aes(x = u, y = mu_hat, group=u))+geom_violin()+
  labs(
    title = "U plot",
    x = "True u",
    y = "Average esimate of u")

mu_hat_plot

```

# plot of mu_hat in samples for which the null was rejected
```{r}
normal4 = function(n = 30, mu, sigma = 5){
  x = rnorm(n = 30, mean = mu, sd = sigma)
  
  t.test(x, alternative = c("two.sided"),
         mu = 0, paired = FALSE, var.equal = FALSE,
         conf.level = 0.95) %>% 
    broom::tidy() %>% 
    filter(p.value<0.05) %>% 
    mutate(
    mu_hat_2 = mean(x)
  ) 
}

normal_df_4 = 
  tibble(u = c(1,2,3,4,5,6)) %>% 
  mutate(
    output_lists = map(.x = u, ~rerun(5000, normal4(mu =.x))), 
    estimate_dfs =  map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs) %>% 
    select(u, mu_hat_2)

mu_hat_2_plot = normal_df_4 %>% 
  ggplot(aes(x = u, y = mu_hat_2, group=u))+geom_violin()+
  labs(
    title = "U plot in samples for which the null was rejected",
    x = "True u",
    y = "Average esimate of u")+
scale_y_continuous(
    breaks = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))

mu_hat_2_plot

```

The sample average of u across tests for which the null is rejected is not equal to the true value of u, because the distribution of u for the sample is skewed. 